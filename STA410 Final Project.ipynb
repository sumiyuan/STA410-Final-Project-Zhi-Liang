{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "319ebb62",
   "metadata": {},
   "source": [
    "# STA410 Final Project: Bayesian Model Selector\n",
    "Zhi-Liang Yuan(1007852940)\n",
    "\n",
    "### Background Information\n",
    "The basis of this course project is a python implementation of the paper *Understanding Predictive Information Criteria For Bayesian Models* written by Andrew Gelman et al. \n",
    "This project seeks to create a python package that allows the user to calculate these predictive informations such as AIC, WAIC, LOOCV, and BIC from the class object. This jupyter hub project can be easily converted into a python file and exported the classes to be used as a package, but for the sake of simplicity I have just implemented the code for the classes in this notebook so it can be easily called upon and tested"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae1a7f2",
   "metadata": {},
   "source": [
    "#### Bayesian Model Class\n",
    "This class is created so that it would create the models for the BayesianModelSelector class to use so it doesn't need to be bogged down by the calculation of variables, and instead can just use them to calculate the criterias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a054ace1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44701e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianModel:\n",
    "    \"\"\"\n",
    "    Bayesian Model Class,\n",
    "    created so that it would be easier to store and call upon attribute of the model from the selector\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y):\n",
    "        \"\"\"\n",
    "        constructor of bayesian model class\n",
    "\n",
    "        :param X: X\n",
    "        :param y: y\n",
    "        \"\"\"\n",
    "        # Store the data in the object as well\n",
    "        X = sm.add_constant(X, prepend=True)\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.n, self.p = X.shape\n",
    "\n",
    "        # Fit a model using OLS\n",
    "        self.model = sm.OLS(y, X)\n",
    "        self.result = self.model.fit()\n",
    "\n",
    "        # Extract MLE estimates\n",
    "        self.beta_hat = self.result.params\n",
    "        self.cov_beta_hat = self.result.cov_params()\n",
    "        # Use unbiased estimate of variance or from fit\n",
    "        self.sigma2_hat = self.result.mse_resid\n",
    "        self.sigma_hat = np.sqrt(self.sigma2_hat)\n",
    "        # compute diagonal hat matrix\n",
    "        XtX_inv = np.linalg.inv(X.T @ X)\n",
    "        H = X @ XtX_inv @ X.T\n",
    "        h_diag = np.diagonal(H)\n",
    "        self.h_diag = h_diag\n",
    "\n",
    "    def draw_posterior_samples(self, n, seed=123123):\n",
    "        \"\"\"\n",
    "        draw_posterior_samples, approximate the posterior draws multivariate normal, this allows us to avoid complicated\n",
    "        posterior functions, and it should work well enough for the scope of this course project\n",
    "\n",
    "        :param n: number of draws\n",
    "        :param seed: the seed of the draw\n",
    "        :return: returns the posterior samples\n",
    "        \"\"\"\n",
    "        # create a rng variable so we can control the seed of the draw\n",
    "        rng = np.random.default_rng(seed)\n",
    "        draws = rng.multivariate_normal(self.beta_hat, self.cov_beta_hat, size=n)\n",
    "        return draws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8124de7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.08351987e-01 -4.70185399e-01 -4.28220707e-01 -1.49412899e+00\n",
      "   1.99955020e-01 -1.35404530e+00  4.33877901e-01 -1.00318276e+00\n",
      "   9.80344017e-01  1.72905202e+00 -1.87713225e+00]\n",
      " [ 7.19873478e-02  1.90308412e+00  3.44373206e+00 -3.68004670e+00\n",
      "   2.73491844e+00 -3.20606223e+00  1.46431639e+00  1.22210005e+00\n",
      "   7.89667877e-01  5.07870535e-01 -6.21936616e-01]\n",
      " [ 1.89992057e-01  1.54117711e+00 -2.66472021e+00  2.37542049e-01\n",
      "   1.19650805e+00 -1.48534742e+00  1.42934696e+00  1.26177310e+00\n",
      "   1.52642018e+00 -4.69690124e-01 -9.21227422e-01]\n",
      " [ 4.29048496e-01  9.88631570e-01 -6.50462378e-01 -1.75245790e+00\n",
      "  -3.33070203e-01 -3.70449935e+00  1.17052249e+00  5.14507043e-01\n",
      "   9.08714914e-01 -4.57302642e-02 -4.36808049e-01]\n",
      " [ 6.95206968e-01  5.08027952e-01 -1.15916865e+00  8.86882242e-02\n",
      "   3.16170671e-02 -1.62341991e+00  1.15600142e+00  3.54531301e-03\n",
      "   2.65408534e+00  3.97824278e-01 -1.56372777e+00]\n",
      " [-5.56789934e-02  1.14184156e-01  1.69743816e+00 -3.03731147e+00\n",
      "  -6.79075773e-01 -2.48668583e+00 -3.49203300e-01  9.24033735e-01\n",
      "   1.41643074e+00  1.00096552e+00 -3.74309935e-01]\n",
      " [-6.03222606e-03  3.57053948e+00  4.86290692e+00 -3.09207691e+00\n",
      "   2.62301432e+00 -6.32327526e+00  4.04922680e+00  6.27134176e-01\n",
      "   2.18593087e+00  2.53900228e-01  7.68732703e-01]\n",
      " [-6.00366330e-01  9.01779342e-01  5.35992613e-01 -2.46923904e+00\n",
      "   7.42904527e-01 -1.02075517e+00  1.57155705e+00  4.24966217e-01\n",
      "   1.48914338e+00  9.25379989e-01 -1.55505070e+00]\n",
      " [ 3.61833734e-01  1.20700501e-01  7.58272226e-01 -5.32231683e-01\n",
      "  -3.13603336e-01 -4.27734694e+00  1.73975724e+00 -5.73194048e-01\n",
      "   3.10983869e-01  1.53906484e+00 -7.93867190e-01]\n",
      " [ 4.91209567e-01  2.85494591e+00  3.31468949e+00 -5.17315587e+00\n",
      "   1.26395494e+00 -4.00259082e+00  2.05196507e-01  2.58868190e+00\n",
      "   5.41997093e-01 -5.31083183e-02  1.44988384e+00]]\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "# test cell\n",
    "mtcars = sm.datasets.get_rdataset(\"mtcars\")\n",
    "y = mtcars.data[['mpg']].values\n",
    "y = y - y.mean()\n",
    "X = mtcars.data[['cyl', 'disp', 'hp', 'drat', 'wt', 'qsec', 'vs', 'am', 'gear', 'carb']].values\n",
    "X = (X - X.mean(axis=0))\n",
    "X = X / (X ** 2).mean(axis=0) ** 0.5\n",
    "b_1 = BayesianModel(X=X, y=y)\n",
    "\n",
    "print(b_1.draw_posterior_samples(10))\n",
    "print(len(b_1.h_diag))\n",
    "\n",
    "longley_data = sm.datasets.get_rdataset(\"longley\")\n",
    "y_2 = longley_data.data[['GNP']].values\n",
    "y_2 = y_2 - y_2.mean()\n",
    "X_2 = longley_data.data[['Employed', 'GNP.deflator', 'Unemployed', 'Armed.Forces', 'Population', 'Year']].values\n",
    "X_2 = (X_2 - X_2.mean(axis=0))\n",
    "X_2 = X_2 / (X_2 ** 2).mean(axis=0) ** 0.5\n",
    "b_2 = BayesianModel(X=X_2, y=y_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde30ea0",
   "metadata": {},
   "source": [
    "### BayesianModelSelector class\n",
    "The BayesianModelSelector class will be the main class object for this project for it calculates the different metrics of the models\n",
    "\n",
    "The class will calculate the matrics for BayesianModel class objects which is created using the class structure above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "391cbfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianModelSelector:\n",
    "    \"\"\"\n",
    "    Bayesian Model Selector Class\n",
    "    This class will act as the main class that allows the user to add/remove, and calculate the different metrics that\n",
    "    measure the quality of a model\n",
    "    class variables:\n",
    "        models : dict(name: string) -> model (BayesianModel)\n",
    "    Methods:\n",
    "        add_model: adds model to the models dict\n",
    "        remove_model: remove model from the models dict\n",
    "        calc_loo : calculates the LOO\n",
    "        calc_waic : calculates waic\n",
    "        calc_aic : calculates aic\n",
    "        calculate_model_selector : calculates the selected methods\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        constructor of the class, create a private models variable\n",
    "        \"\"\"\n",
    "        self.models = {}\n",
    "        \n",
    "    def add_model(self, name, model):\n",
    "        \"\"\"\n",
    "        add_model, adds a BayesianModel model object into the models dictionary\n",
    "        :param name: name of the model (String)\n",
    "        :param model: bayesian model (BayesianModel)\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        if name not in self.models:\n",
    "            self.models[name] = model\n",
    "        else:\n",
    "            print(f\"Model '{name}' is already in the model, if you wish to update please delete existing model first\")\n",
    "\n",
    "    def remove_model(self, name):\n",
    "        \"\"\"\n",
    "        remove_model, removes the bayesian model object with 'name' from the models dictionary\n",
    "        :param name: name of the model (String)\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        if name in self.models:\n",
    "            self.models.pop(name)\n",
    "        else:\n",
    "            print(f\"'{name}' is not a model in the dictionary\")\n",
    "\n",
    "    def get_all_models(self):\n",
    "        \"\"\"\n",
    "        get all the models' names\n",
    "        :return: the name of all the stored models\n",
    "        \"\"\"\n",
    "        return [*self.models]\n",
    "    \n",
    "    def calc_aic(self, name):\n",
    "        \"\"\"\n",
    "        calculate the aic of the model using the formula AIC = -2 log p(y | \\theta) + 2*k\n",
    "        :param name: name (String) of the model that we want to calculate the aic for\n",
    "        :return: calculated aic value (float)\n",
    "        \"\"\"\n",
    "        # check if the model is in the model\n",
    "        if name not in self.models:\n",
    "            print(f\"'{name}' is not a model in the dictionary\")\n",
    "            return None\n",
    "        \n",
    "        # calculate the log_likelihood of the model\n",
    "        curr_model = self.models[name]\n",
    "        log_likelihood = curr_model.result.llf\n",
    "\n",
    "        # get the number of parameters of the model, +1 for the intercept that we include\n",
    "        k = curr_model.result.df_model + 1\n",
    "\n",
    "        # aic is calculated as -2 * log_likelihood + 2*k\n",
    "        aic = -2*log_likelihood + 2*k\n",
    "        return aic\n",
    "    \n",
    "    def calc_bic(self, name):\n",
    "        \"\"\"\n",
    "        calculate the bic based on the formula, BIC = -2 log p(y | \\theta) + log(n)*k \n",
    "        :param name: name (String) of the model\n",
    "        :return: calculated BIC (float)\n",
    "        \"\"\"\n",
    "        # check if the model is in the model\n",
    "        if name not in self.models:\n",
    "            print(f\"'{name}' is not a model in the dictionary\")\n",
    "            return None\n",
    "\n",
    "        # calculate the log_likelihood of the model\n",
    "        curr_model = self.models[name]\n",
    "        log_likelihood = curr_model.result.llf\n",
    "\n",
    "        # get the number of parameters of the model, +1 for the intercept that we include\n",
    "        k = curr_model.result.df_model + 1\n",
    "\n",
    "        # number of observations/samples\n",
    "        n = curr_model.result.nobs\n",
    "\n",
    "        # calculate the BIC based on the formula BIC = -2 log p(y | \\theta) + log(n)*k\n",
    "        bic = -2 * log_likelihood + np.log(n) * k\n",
    "        return bic\n",
    "    \n",
    "    def calc_waic(self, name, num=1000, seed=123123):\n",
    "        \"\"\"\n",
    "        calculate the waic for this model, based on the formula waic = -2(lppd - p_waic)\n",
    "        :param model: name of the model (String)\n",
    "        :param num: number of posterior draws (int)\n",
    "        :param seed: seed of the random draw (int)\n",
    "        :return: the calculated waic (float)\n",
    "        \"\"\"\n",
    "        # for waic we want to find the point log likelihood based on posterior draws, therefore we would need to\n",
    "        # calculate the likelihood for each point, thus,\n",
    "\n",
    "        # check if the model is in the model\n",
    "        if name not in self.models:\n",
    "            print(f\"'{name}' is not a model in the dictionary\")\n",
    "            return None\n",
    "\n",
    "        # calculate the log_likelihood of the model\n",
    "        model = self.models[name]\n",
    "        # posterior draws based on the model\n",
    "        draws = model.draw_posterior_samples(num, seed)\n",
    "\n",
    "        # create an empty log likelihood array for storing\n",
    "        log_likelihood = np.zeros((model.n, num))\n",
    "\n",
    "        # loop over the draws to calculate the log likelihood for each point\n",
    "        for x in range(num):\n",
    "            curr_draw = draws[x]\n",
    "\n",
    "            # need to calculate the residual\n",
    "            mu = model.X @ curr_draw\n",
    "            curr_resid = model.y.ravel() - mu\n",
    "\n",
    "            # we can now calculate the log likelihood for each posterior draw\n",
    "            log_likelihood[:, x] = (\n",
    "                -0.5 * np.log(2.0 * np.pi * model.sigma2_hat)\n",
    "                - 0.5 * (curr_resid**2) / model.sigma2_hat\n",
    "            )\n",
    "\n",
    "        max_likelihood = np.max(log_likelihood, axis=1, keepdims=True)\n",
    "        # we want to calculate the llpd for each draw\n",
    "        likelihood_i = np.exp(log_likelihood - max_likelihood)\n",
    "        # get the average likelihood across the draw\n",
    "        avg_likelihood_i = np.mean(likelihood_i, axis=1)\n",
    "        # now we can calcualte the lppd for this draw\n",
    "        lppd_i = np.log(avg_likelihood_i) + np.squeeze(max_likelihood, axis=1)\n",
    "\n",
    "        # Summation across all draws to get the lppd\n",
    "        lppd = np.sum(lppd_i)\n",
    "\n",
    "        # we now want to calculate the p_waic\n",
    "        var_log_likelihood = np.var(log_likelihood, axis=1, ddof=1)  # sample var across draws\n",
    "        p_waic = np.sum(var_log_likelihood)\n",
    "\n",
    "        elppd_waic = lppd - p_waic\n",
    "        waic_value = -2.0 * elppd_waic\n",
    "\n",
    "        return waic_value\n",
    "    \n",
    "    def calc_loocv(self, name):\n",
    "        \"\"\"\n",
    "        calculate the loocv\n",
    "        :param name: name (String) of the model\n",
    "        :return: calculated BIC (float)\n",
    "        \"\"\"\n",
    "        # check if the model is in the model\n",
    "        if name not in self.models:\n",
    "            print(f\"'{name}' is not a model in the dictionary\")\n",
    "            return None\n",
    "\n",
    "        # calculate the log_likelihood of the model\n",
    "        curr_model = self.models[name]\n",
    "        y_hat = curr_model.result.fittedvalues\n",
    "        resid = curr_model.result.resid\n",
    "\n",
    "        # to calculate the predicted value at teach point\n",
    "        y_hat_loo = y_hat - resid / curr_model.h_diag\n",
    "\n",
    "        # calculate the residual \n",
    "        e_loo = curr_model.y.ravel() - y_hat_loo\n",
    "\n",
    "        # calculate the pointwise likelihood\n",
    "        likelihood_loo_i = -0.5 * np.log(2.0 * np.pi * curr_model.sigma2_hat) \\\n",
    "                   - 0.5 * (e_loo ** 2) / curr_model.sigma2_hat\n",
    "        \n",
    "        return np.sum(likelihood_loo_i)\n",
    "    \n",
    "    def calc_metrics(self, name, metric, num=1000, seed=123123):\n",
    "        # check if the model is in the model\n",
    "        if name not in self.models:\n",
    "            print(f\"'{name}' is not a model in the dictionary\")\n",
    "            return None\n",
    "        \n",
    "        # determine which metric needs to be calculated\n",
    "        if metric == \"aic\":\n",
    "            curr_aic = self.calc_aic(name)\n",
    "            print(f\"The AIC metric for model '{name}' is '{curr_aic}', the lower the AIC the better\")\n",
    "            return curr_aic\n",
    "        elif metric == \"bic\":\n",
    "            curr_bic = self.calc_bic(name)\n",
    "            print(f\"The BIC metric for model '{name}' is '{curr_bic}', the lower the BIC the better\")\n",
    "            return curr_bic\n",
    "        elif metric == \"waic\":\n",
    "            curr_waic = self.calc_waic(name, num, seed)\n",
    "            print(f\"The WAIC metric for model '{name}' is '{curr_aic}' on '{num}' posterior draws, the lower the WAIC the better\")\n",
    "            return curr_waic\n",
    "        elif metric == \"loocv\":\n",
    "            curr_loocv = self.calc_loocv(name)\n",
    "            print(f\"The LOOCV metric for model '{name}' is '{curr_loocv}', the higher the LOOCV the better\")\n",
    "            return curr_loocv\n",
    "        elif metric == \"all\":\n",
    "            curr_aic = self.calc_aic(name)\n",
    "            curr_bic = self.calc_bic(name)\n",
    "            curr_waic = self.calc_waic(name, num, seed)\n",
    "            curr_loocv = self.calc_loocv(name)\n",
    "            print(f\"The AIC metric for model '{name}' is '{curr_aic}', the lower the AIC the better \\n\" +\n",
    "                  f\"The BIC metric for model '{name}' is '{curr_bic}', the lower the BIC the better \\n\" +\n",
    "                  f\"The WAIC metric for model '{name}' is '{curr_aic}' on '{num}' posterior draws, the lower the WAIC the better \\n\" +\n",
    "                  f\"The LOOCV metric for model '{name}' is '{curr_loocv}', the higher the LOOCV the better\")\n",
    "            return [curr_aic, curr_bic, curr_waic, curr_loocv]\n",
    "        else:\n",
    "            print(\"There is an error with the metric you have entered, please try again\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "011bc10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b1', 'longley']\n",
      "['b1', 'longley']\n",
      "161.70981043447966\n",
      "177.83290536527664\n",
      "163.62671982667138\n",
      "-323.69550597899774\n",
      "The AIC metric for model 'b1' is '161.70981043447966', the lower the AIC the better \n",
      "The BIC metric for model 'b1' is '177.83290536527664', the lower the BIC the better \n",
      "The WAIC metric for model 'b1' is '161.70981043447966' on '1000' posterior draws, the lower the WAIC the better \n",
      "The LOOCV metric for model 'b1' is '-323.69550597899774', the higher the LOOCV the better\n",
      "[161.70981043447966, 177.83290536527664, 163.62671982667138, -323.69550597899774]\n",
      "\n",
      "\n",
      "The AIC metric for model 'longley' is '83.80410064913389', the lower the AIC the better \n",
      "The BIC metric for model 'longley' is '89.21222170481235', the lower the BIC the better \n",
      "The WAIC metric for model 'longley' is '83.80410064913389' on '1000' posterior draws, the lower the WAIC the better \n",
      "The LOOCV metric for model 'longley' is '-104.3623266785628', the higher the LOOCV the better\n",
      "[83.80410064913389, 89.21222170481235, 84.8996596314523, -104.3623266785628]\n"
     ]
    }
   ],
   "source": [
    "# test cell 2\n",
    "selector = BayesianModelSelector()\n",
    "selector.add_model(\"b1\",b_1)\n",
    "selector.add_model(\"longley\", b_2)\n",
    "print(selector.get_all_models())\n",
    "selector.remove_model(\"longley\")\n",
    "selector.add_model(\"longley\", b_2)\n",
    "print(selector.get_all_models())\n",
    "print(selector.calc_aic(\"b1\"))\n",
    "print(selector.calc_bic(\"b1\"))\n",
    "print(selector.calc_waic(\"b1\"))\n",
    "print(selector.calc_loocv(\"b1\"))\n",
    "print(selector.calc_metrics(\"b1\", \"all\"))\n",
    "print(\"\\n\")\n",
    "print(selector.calc_metrics(\"longley\", \"all\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764058cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
